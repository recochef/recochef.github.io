<!DOCTYPE html>
<html lang="en">

<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-5F9Y9HC95G"></script>
      <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag("js", new Date());
      gtag("config", "G-5F9Y9HC95G");
      </script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="Recommend products using word2vec">
    <meta property="og:type" content="blog">
  <title>Recommend products using word2vec</title>
<link rel="icon" type="image/png" href="./favicon.png"/>
  <!-- Favicon -->
    <link rel="shortcut icon" target="_blank" href="ðŸŒ€">
    <link rel="stylesheet" type="text/css" target="_blank" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    target="_blank" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" target="_blank" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" target="_blank" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" target="_blank" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
    <a href="index">
      <div class="Navbar__Btn"><span>ðŸŒ€</span> <span>Home</span></div>
    </a>
                                                                                                                                                                              </nav>
  <header class="Header">
          <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
        <h1 class="Header__Title">Recommend products using word2vec</h1>
          </header>
      <article id="https://www.notion.so/6c343fdc8c114147a041cd6adfdd3903" class="PageRoot"><div id="https://www.notion.so/a2be5e145ee84e58b55056643096a934" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Todayâ€™s world is a small, deeply interconnected web. The internet has seemingly infinite potential, and in the post COVID world, the effect of the internet on our lives will just increase. Businesses are developing advanced solutions in e-commerce space to win over clients and one common focus area is personalized recommendations. Recommendation systems enable businesses to maximize their ROI based on the information they can gather on each customerâ€™s preferences and purchases.</span></span></p></div><div id="https://www.notion.so/b893c398d0f34215be7e1004d03e11b3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">While building the recommendation system it is very common to use a traditional collaborative filtering algorithm such as item-item and user-item filtering. Basically, these algorithms are item-based in the sense that they analyse item-item relations to produce item similarities and focused on learningÂ </span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">similarities between users and items simultaneously</em></span><span class="SemanticString">Â to provide recommendations. What if the user or item information is not available, how to build a more robust recommendation system? This led us to try to discover techniques from deep learning that can be used to overcome this limitation.</span></span></p></div><div id="https://www.notion.so/3c0b06adf4e44831b2b750eba2d6e42d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">We want to focus on an extension of the Word2Vec model, called Item2Vec for item-based Collaborative Filtering that produces embedding for items in a latent space. The method is capable of inferring item to item (items might refer to sequences or words) relations even when user/item information is not available, which basically means it learns the item similarities by embedding items in a low dimensional space regardless of the users.</span></span></p></div><div id="https://www.notion.so/4b37770342c74883bb1c9c796d8cbbed" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Problem statement: </strong></span><span class="SemanticString">Create a system that automatically recommends a certain number of products to the consumers on an E-commerce website based on the past purchase behavior of the consumers.</span></span></p></div><div id="https://www.notion.so/00fad7f1186843759bd3f7a98f072119" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">A person involved in sports-related activities might have an online buying pattern similar to this:</span></span></p></div><div id="https://www.notion.so/a5f5d3cd7b364591a8514f5f453de444" class="Image Image--Normal"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe1a13465-392c-44aa-b741-53a84a253ff4%2FUntitled.png?width=704&amp;table=block&amp;id=a5f5d3cd-7b36-4591-a851-4f5f453de444"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe1a13465-392c-44aa-b741-53a84a253ff4%2FUntitled.png?width=704&amp;table=block&amp;id=a5f5d3cd-7b36-4591-a851-4f5f453de444" style="width:704px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Purchase history of the consumer</span></span></figcaption></figure></div><div id="https://www.notion.so/1712d58ae4b84aac9dc86ed3e8c00156" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">If we can represent each of these products by a vector, then we can easily find similar products. So, if a user is checking out a product online, then we can easily recommend him/her similar products by using the vector similarity score between the products.</span></span></p></div><h3 id="https://www.notion.so/6bd2a9e221554b43941d7b2b9aa24944" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/6bd2a9e221554b43941d7b2b9aa24944"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Soâ€¦ What is Word2vec?</strong></span></span></h3><div id="https://www.notion.so/421641ccc1a745e884f3f5315db5bee8" class="Image Image--Normal"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcce7c894-3039-4c88-9537-7ad4cfb62689%2FUntitled.png?width=387&amp;table=block&amp;id=421641cc-c1a7-45e8-84f3-f5315db5bee8"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fcce7c894-3039-4c88-9537-7ad4cfb62689%2FUntitled.png?width=387&amp;table=block&amp;id=421641cc-c1a7-45e8-84f3-f5315db5bee8" style="width:387px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/72937db66a0243a49764e09be71f273d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Word2vec is a class of neural network models that were initially introduced for learning word embeddings that are highly useful for Natural Language Processing tasks. In recent years, the technique has also been applied to more general machine learning problems including product recommendations. The neural network takes in a large corpus of text, analyzes it, and for each word in the vocabulary, generates a vector of numbers that represent that word. Those vectors of numbers are what we are after, because as weâ€™ll see, they encode important information about the meaning of the word in relation to the context in which it appears.</span></span></p></div><div id="https://www.notion.so/d4f4e4e7290941a39e49e281c43df06b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">There are two main models defined: theÂ </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Continuous Bag-of-Words</strong></span><span class="SemanticString">Â model and theÂ </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Skip-gram</strong></span><span class="SemanticString">Â model.</span></span></p></div><div id="https://www.notion.so/d96431fc240c4e3a8e4dff861a81912d" class="Image Image--PageWidth"><figure><a target="_blank" href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0e926efc-b14e-472f-b04f-85626af23e98%2FUntitled.png?width=1012&amp;table=block&amp;id=d96431fc-240c-4e3a-8e4d-ff861a81912d"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0e926efc-b14e-472f-b04f-85626af23e98%2FUntitled.png?width=1012&amp;table=block&amp;id=d96431fc-240c-4e3a-8e4d-ff861a81912d" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/3fe211f34a2a495aaae85b11bd9673e4" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h3 id="https://www.notion.so/95abf79907fe4e07ab378df06691e7a2" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" target="_blank" href="#https://www.notion.so/95abf79907fe4e07ab378df06691e7a2"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">References</span></span></h3><ul class="BulletedListWrapper"><li id="https://www.notion.so/5140939f489843eeb129af1a1ec1db54" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://www.analyticsvidhya.com/blog/2019/07/how-to-build-recommendation-system-word2vec-python/">https://www.analyticsvidhya.com/blog/2019/07/how-to-build-recommendation-system-word2vec-python/</a></span></span></li><li id="https://www.notion.so/103598d878f54bd2ba5d9b2cd3f124bf" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://mccormickml.com/2018/06/15/applying-word2vec-to-recommenders-and-advertising/">https://mccormickml.com/2018/06/15/applying-word2vec-to-recommenders-and-advertising/</a></span></span></li><li id="https://www.notion.so/c789da378ba149dbb89b87eb53812266" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://www.analyticsinsight.net/building-recommendation-system-using-item2vec/">https://www.analyticsinsight.net/building-recommendation-system-using-item2vec/</a></span></span></li><li id="https://www.notion.so/07b43f9239c44f28884a1138eee6450b" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://towardsdatascience.com/using-word2vec-for-music-recommendations-bb9649ac2484">https://towardsdatascience.com/using-word2vec-for-music-recommendations-bb9649ac2484</a></span></span></li><li id="https://www.notion.so/50ed902fe76a4562ad51d57335313b91" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" target="_blank" href="https://capablemachine.com/2020/06/23/word-embedding/">https://capablemachine.com/2020/06/23/word-embedding/</a></span></span></li></ul></article>  <footer class="Footer">
        <div>&copy; RecoChef 2021</div>
        <div>&centerdot;</div>
        <div>Powered by <a target="_blank" href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>